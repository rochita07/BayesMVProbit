---
title: "BayesMVProbitVignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BayesMVProbitVignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, cache = T, message = F}
library(BayesMVProbit)
```

# MUltivariate Nominal 

## Data structure

Suppose for each subject i, $i = 1,..,n$ there are g nominal measures, the first with $p_1$  levels, the next with $p_2$ levels, and so on up to the last with $p_g$ levels.

The data looks like, 

$$ y_i = 
\begin{bmatrix}
y_{11i}\\
y_{12i}\\
.\\
y_{1p_1i}\\
.\\
.\\
y_{g1i}\\
.\\
y_{g{p_g}i}
\end{bmatrix}
$$

We consider $y_{qji} = 1$ if i th subject has j th outcome in q th nominal measure, $y_{qji} = 0$ otherwise.

We assume each of these g nominal measures follows an MNP model.
 
To consider additive and multiplicative redundancy problem we assume, for the q-th measure, q = 1, ., g, there is a
 $p_{q-1}$ dimensional utility vector $z_{qi} = (z_{q1i},.. ,z_{q{p_q}i})$

$$z_{qji} = \beta_{qj}^t x_{qi} + \epsilon_{qji}$$ where $\beta_{qj}^t$ is the vector of  regression coefficient for jth level of qth nominal measure and $x_{qi}$ be covariate vector for q th level and for ith subject and $\epsilon_{qji}$ is the corresponding error term. 

$$z_{qi} = B_q  x_{qi}  + \epsilon_{qi}$$  where $B_q$ is the matrix of coefficients for qth nominal measure 

Alternatively, for making computation easier, we write $\beta_q$ matrix in vector form.

$$z_{qi} = X_{qi} \beta_q + \epsilon_{qi}  $$ $\beta_q$ is the vectorized form of $B_q$ matrix, (row wise stacked) where and $X_{qi} = I_{p_q-1} \otimes x_{qi}^t$ is matrix of covariates.

Here, $\epsilon_i \sim N(0, \Sigma)$

For compact notation, Now we define, $d_i = (d_{1i}, ., d_{gi})$ denote the index vector of the alternatives the i-th subject chooses for the g measures.

$d_{qi} = j \iff y_{qji} =1$ for j = 1, 2, .. , $p_q - $ and $d_{qi} = 0 \iff y_{qji} = p_q $
 
 $d_{qi} = 0 \quad if \quad max_{1 \leq l \leq p_q -1}  \quad z_{qli} < 0 $

$d_{qi} = j \quad if \quad max_{1 \leq l \leq p_q 1}  \quad z_{qli} = z_{qji} > 0 $

for i = 1, .. ,n, and  q = 1, .. ,g



## Data generation example [Binary data : 2 nominal measures, respectively have $p_1 = 3$ and $p_2 = 4$ levels]

```{r, cache = TRUE}

variable_dim = 2 # no of variables
category = c(3,4) # no of levels for each variable
n = 50 # no of subjects
covariate_num = c(2,3) # no of covariates for each level
iter = 20 # no of iterartion
burn = 10 # no of burn in
z_dim = sum(category) - length(category)  ## dimension of z for each subject
beta_dim = sum((category - 1) * covariate_num)

set.seed(1287)

beta_act1 = matrix(rep(2, (category[1]-1) * covariate_num[1]), nrow = category[1]-1)
  ## matrix of regression coefficient for 1st nominal measure
beta_act2 = matrix(rep(3, (category[2]-1) * covariate_num[2]), nrow = category[2]-1)
 ## matrix of regression coefficient for 1st nominal measure
beta_act = as.vector(c(beta_act1, beta_act2)) ## vectorized form of beta
## should be of same length  as beta_dim

x1_mat = matrix(rnorm(n * covariate_num[1]), nrow = covariate_num[1] ) # each column is for each subject, each row is for each  covariates
x2_mat = matrix(rnorm(n * covariate_num[2]), nrow = covariate_num[2] ) # each column is for each subject, each row is for each  covariates
x_list = list(x1_mat, x2_mat)  # input should be given as list 

z1_mat = beta_act1 %*% x1_mat 
z2_mat = beta_act2 %*% x2_mat

```

Sigma matrix (variance covariance matrix for error) should be defined by user, otherwise Identity matrix would be considered as by default. In this case Sigma matrix is considered as mentioned in the paper(mentioned in Readme)

```{r, cache= TRUE}

sig1 = matrix(c(1, 0.36, 0.36, 0.81), nrow = 2)
sig2 = matrix(c(1, 0.45, 0.24, 0.45, 0.81, 0.41, 0.24, 0.41, 0.9), nrow =3)
sig3 = matrix(c(rep(0.2, 6)), nrow =2)
sig4 = matrix(c(rep(0.2, 6)), nrow =3)
sig_gen = as.matrix(rbind(cbind(sig1, sig3), cbind(sig4, sig2))) ## Final sigma 
  

```
Example of Matrix for variance covariance matrix for error (user should provide):

```{r, cahe =TRUE}
sig_gen

```

```{r, cache = TRUE}

e_mat = MASS::mvrnorm(n , mu = rep(0, z_dim) , Sigma = sig_gen )  # Generation of error term
e_mat = t(e_mat) # each column is for each subject

#Generation of  Z vectors for each subject, each column is for each subject
z_mat = matrix(rep(0, n * z_dim), ncol = n) ## each column is for each subject

for(i in 1: n){
  
  z_mat[, i] = c(z1_mat[, i], z2_mat[, i]) + e_mat[, i]
  
}


#Computation of d matrix ## user should provide this input

d = matrix(rep(0, n * length(category)), ncol = n)  # each col corresponds to each subject
q = rep(1, length(category) + 1)  ## the indicator to compute d matrix (as mentioned in the paper)
q[1] = 1
category_cum_sum = cumsum(category)

for(g in 2: length(q))
{
  q[g] = category_cum_sum[g-1] - (g-1 - 1)    ## ex: p1 + p2 + p3 - 2
}


for(i in 1: n)
{ 
  for(j in 1:variable_dim )
  {
    x = z_mat[ q[j] : (q[j+1] - 1) , i]
    # print(x)
    
    if(max(x) < 0)
    {
      d[j, i] = 0
    }
    if(max(x) >= 0)
    {
      d[j, i] = which.max(x)
    }
  }
}

```

Example of d matrix (user should provide):

```{r, cache =TRUE}
d
```
